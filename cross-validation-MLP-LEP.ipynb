{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "K=5\n",
    "CATEGORIES = ['Electron','Muon','Tau','Quark']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"XLEP.pickle\",\"rb\")\n",
    "X0 = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"yLEP.pickle\",\"rb\")\n",
    "z0 = pickle.load(pickle_in)\n",
    "\n",
    "X = np.array(X0)\n",
    "\n",
    "y = np.array(z0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_data</th>\n",
       "      <th>X_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.264923095703125, -0.08237313479185104, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.9543304443359375, 0.46060577034950256, 0.46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.1748199462890625, -0.9757654666900635, -0.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, -0.8283840417861938, -0.8284099102020264...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[4.1381988525390625, 0.46575456857681274, 0.50...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_data                                             X_data\n",
       "0       0  [0.264923095703125, -0.08237313479185104, -0.0...\n",
       "1       1  [0.9543304443359375, 0.46060577034950256, 0.46...\n",
       "2       0  [0.1748199462890625, -0.9757654666900635, -0.9...\n",
       "3       1  [0.0, -0.8283840417861938, -0.8284099102020264...\n",
       "4       0  [4.1381988525390625, 0.46575456857681274, 0.50..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_x = pd.DataFrame({'X_data': [X[i] for i in range(len(X))] })\n",
    "df_y = pd.DataFrame({'y_data': y })\n",
    "\n",
    "df_final = pd.concat([df_y,df_x], axis=1)\n",
    "df_final.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training K-times with shufled data and savind the predictions of each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "interval = int(len(X)/K)\n",
    "X_u = df_final['X_data']\n",
    "y_u = df_final['y_data']\n",
    "    \n",
    "Xinterval = []\n",
    "yinterval = []\n",
    "for i in range(K):\n",
    "    xsub_set = []\n",
    "    ysub_set = []\n",
    "    xsub_set = np.array([X_u[j] for j in range(i*interval,(i+1)*interval)])\n",
    "    ysub_set = np.array([y_u[j] for j in range(i*interval,(i+1)*interval)])\n",
    "    Xinterval.append(xsub_set)\n",
    "    yinterval.append(ysub_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cointerval = (K-1)*interval\n",
    "interval + cointerval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 320000)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coXinterval = []\n",
    "coyinterval = []\n",
    "for i in range(K):\n",
    "    aaa=[]\n",
    "    bbb=[]\n",
    "    for j in range(K):\n",
    "        if j == i:\n",
    "            pass\n",
    "        else:\n",
    "            aaa.append(Xinterval[j])\n",
    "            bbb.append(yinterval[j])\n",
    "    coXinterval.append(aaa)\n",
    "    coyinterval.append(bbb)\n",
    "\n",
    "for k in range(K):\n",
    "    coXinterval[k] = np.reshape(coXinterval[k],(cointerval,14))\n",
    "    coyinterval[k] = np.reshape(coyinterval[k],(cointerval,1))\n",
    "len(yinterval[2]),len(coyinterval[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 224000 samples, validate on 96000 samples\n",
      "Epoch 1/10\n",
      "224000/224000 [==============================] - 20s 88us/step - loss: 0.1112 - acc: 0.9608 - val_loss: 0.0566 - val_acc: 0.9788\n",
      "Epoch 2/10\n",
      "224000/224000 [==============================] - 18s 81us/step - loss: 0.0612 - acc: 0.9780 - val_loss: 0.0464 - val_acc: 0.9828\n",
      "Epoch 3/10\n",
      "224000/224000 [==============================] - 19s 83us/step - loss: 0.0539 - acc: 0.9804 - val_loss: 0.0415 - val_acc: 0.9839\n",
      "Epoch 4/10\n",
      "224000/224000 [==============================] - 18s 82us/step - loss: 0.0507 - acc: 0.9814 - val_loss: 0.0395 - val_acc: 0.9854\n",
      "Epoch 5/10\n",
      "224000/224000 [==============================] - 17s 76us/step - loss: 0.0493 - acc: 0.9820 - val_loss: 0.0408 - val_acc: 0.9854\n",
      "Epoch 6/10\n",
      "224000/224000 [==============================] - 15s 68us/step - loss: 0.0483 - acc: 0.9823 - val_loss: 0.0366 - val_acc: 0.9865\n",
      "Epoch 7/10\n",
      "224000/224000 [==============================] - 15s 69us/step - loss: 0.0471 - acc: 0.9825 - val_loss: 0.0416 - val_acc: 0.9851\n",
      "Epoch 8/10\n",
      "224000/224000 [==============================] - 19s 84us/step - loss: 0.0462 - acc: 0.9830 - val_loss: 0.0400 - val_acc: 0.9855\n",
      "Epoch 9/10\n",
      "224000/224000 [==============================] - 17s 77us/step - loss: 0.0461 - acc: 0.9830 - val_loss: 0.0369 - val_acc: 0.9856\n",
      "Epoch 10/10\n",
      "224000/224000 [==============================] - 18s 79us/step - loss: 0.0452 - acc: 0.9832 - val_loss: 0.0380 - val_acc: 0.9862\n",
      "80000/80000 [==============================] - 2s 22us/step\n",
      "Train on 224000 samples, validate on 96000 samples\n",
      "Epoch 1/10\n",
      "224000/224000 [==============================] - 19s 83us/step - loss: 0.1094 - acc: 0.9612 - val_loss: 0.0635 - val_acc: 0.9787\n",
      "Epoch 2/10\n",
      "224000/224000 [==============================] - 18s 81us/step - loss: 0.0619 - acc: 0.9776 - val_loss: 0.0453 - val_acc: 0.9809\n",
      "Epoch 3/10\n",
      "224000/224000 [==============================] - 17s 77us/step - loss: 0.0542 - acc: 0.9798 - val_loss: 0.0410 - val_acc: 0.9845\n",
      "Epoch 4/10\n",
      "224000/224000 [==============================] - 18s 79us/step - loss: 0.0515 - acc: 0.9809 - val_loss: 0.0394 - val_acc: 0.9852\n",
      "Epoch 5/10\n",
      "224000/224000 [==============================] - 18s 82us/step - loss: 0.0503 - acc: 0.9815 - val_loss: 0.0392 - val_acc: 0.9858\n",
      "Epoch 6/10\n",
      "224000/224000 [==============================] - 18s 81us/step - loss: 0.0484 - acc: 0.9819 - val_loss: 0.0383 - val_acc: 0.9851\n",
      "Epoch 7/10\n",
      "224000/224000 [==============================] - 17s 77us/step - loss: 0.0471 - acc: 0.9822 - val_loss: 0.0373 - val_acc: 0.9860\n",
      "Epoch 8/10\n",
      "224000/224000 [==============================] - 18s 80us/step - loss: 0.0466 - acc: 0.9827 - val_loss: 0.0361 - val_acc: 0.9861\n",
      "Epoch 9/10\n",
      "224000/224000 [==============================] - 18s 78us/step - loss: 0.0459 - acc: 0.9828 - val_loss: 0.0373 - val_acc: 0.9855\n",
      "Epoch 10/10\n",
      "224000/224000 [==============================] - 18s 82us/step - loss: 0.0454 - acc: 0.9833 - val_loss: 0.0370 - val_acc: 0.9865\n",
      "80000/80000 [==============================] - 2s 21us/step\n",
      "Train on 224000 samples, validate on 96000 samples\n",
      "Epoch 1/10\n",
      "224000/224000 [==============================] - 19s 85us/step - loss: 0.1118 - acc: 0.9611 - val_loss: 0.0531 - val_acc: 0.9807\n",
      "Epoch 2/10\n",
      "224000/224000 [==============================] - 18s 81us/step - loss: 0.0610 - acc: 0.9779 - val_loss: 0.0468 - val_acc: 0.9828\n",
      "Epoch 3/10\n",
      "224000/224000 [==============================] - 18s 81us/step - loss: 0.0536 - acc: 0.9802 - val_loss: 0.0416 - val_acc: 0.9846\n",
      "Epoch 4/10\n",
      "224000/224000 [==============================] - 20s 87us/step - loss: 0.0500 - acc: 0.9815 - val_loss: 0.0397 - val_acc: 0.9856\n",
      "Epoch 5/10\n",
      "224000/224000 [==============================] - 19s 84us/step - loss: 0.0481 - acc: 0.9823 - val_loss: 0.0403 - val_acc: 0.9856\n",
      "Epoch 6/10\n",
      "224000/224000 [==============================] - 21s 95us/step - loss: 0.0470 - acc: 0.9828 - val_loss: 0.0383 - val_acc: 0.9855\n",
      "Epoch 7/10\n",
      "224000/224000 [==============================] - 19s 83us/step - loss: 0.0457 - acc: 0.9830 - val_loss: 0.0363 - val_acc: 0.9860\n",
      "Epoch 8/10\n",
      "224000/224000 [==============================] - 18s 80us/step - loss: 0.0454 - acc: 0.9832 - val_loss: 0.0375 - val_acc: 0.9857\n",
      "Epoch 9/10\n",
      "224000/224000 [==============================] - 20s 88us/step - loss: 0.0450 - acc: 0.9835 - val_loss: 0.0368 - val_acc: 0.9858\n",
      "Epoch 10/10\n",
      "224000/224000 [==============================] - 19s 83us/step - loss: 0.0449 - acc: 0.9835 - val_loss: 0.0373 - val_acc: 0.9862\n",
      "80000/80000 [==============================] - 2s 21us/step\n",
      "Train on 224000 samples, validate on 96000 samples\n",
      "Epoch 1/10\n",
      "224000/224000 [==============================] - 20s 88us/step - loss: 0.1073 - acc: 0.9627 - val_loss: 0.0553 - val_acc: 0.9788\n",
      "Epoch 2/10\n",
      "224000/224000 [==============================] - 19s 84us/step - loss: 0.0602 - acc: 0.9779 - val_loss: 0.0515 - val_acc: 0.9809\n",
      "Epoch 3/10\n",
      "224000/224000 [==============================] - 19s 86us/step - loss: 0.0546 - acc: 0.9796 - val_loss: 0.0444 - val_acc: 0.9829\n",
      "Epoch 4/10\n",
      "224000/224000 [==============================] - 19s 85us/step - loss: 0.0513 - acc: 0.9810 - val_loss: 0.0409 - val_acc: 0.9847\n",
      "Epoch 5/10\n",
      "224000/224000 [==============================] - 19s 86us/step - loss: 0.0489 - acc: 0.9820 - val_loss: 0.0382 - val_acc: 0.9854\n",
      "Epoch 6/10\n",
      "224000/224000 [==============================] - 19s 85us/step - loss: 0.0478 - acc: 0.9823 - val_loss: 0.0397 - val_acc: 0.9850\n",
      "Epoch 7/10\n",
      "224000/224000 [==============================] - 18s 81us/step - loss: 0.0465 - acc: 0.9829 - val_loss: 0.0388 - val_acc: 0.9856\n",
      "Epoch 8/10\n",
      "224000/224000 [==============================] - 18s 83us/step - loss: 0.0463 - acc: 0.9828 - val_loss: 0.0376 - val_acc: 0.9858\n",
      "Epoch 9/10\n",
      "224000/224000 [==============================] - 18s 82us/step - loss: 0.0455 - acc: 0.9831 - val_loss: 0.0386 - val_acc: 0.9859\n",
      "Epoch 10/10\n",
      "224000/224000 [==============================] - 20s 89us/step - loss: 0.0455 - acc: 0.9832 - val_loss: 0.0373 - val_acc: 0.9853\n",
      "80000/80000 [==============================] - 2s 22us/step\n",
      "Train on 224000 samples, validate on 96000 samples\n",
      "Epoch 1/10\n",
      "224000/224000 [==============================] - 19s 86us/step - loss: 0.1069 - acc: 0.9627 - val_loss: 0.0551 - val_acc: 0.9801\n",
      "Epoch 2/10\n",
      "224000/224000 [==============================] - 18s 82us/step - loss: 0.0599 - acc: 0.9780 - val_loss: 0.0454 - val_acc: 0.9832\n",
      "Epoch 3/10\n",
      "224000/224000 [==============================] - 19s 84us/step - loss: 0.0536 - acc: 0.9802 - val_loss: 0.0459 - val_acc: 0.9831\n",
      "Epoch 4/10\n",
      "224000/224000 [==============================] - 18s 82us/step - loss: 0.0497 - acc: 0.9813 - val_loss: 0.0411 - val_acc: 0.9840\n",
      "Epoch 5/10\n",
      "224000/224000 [==============================] - 18s 81us/step - loss: 0.0489 - acc: 0.9820 - val_loss: 0.0389 - val_acc: 0.9856\n",
      "Epoch 6/10\n",
      "224000/224000 [==============================] - 19s 84us/step - loss: 0.0476 - acc: 0.9823 - val_loss: 0.0401 - val_acc: 0.9836\n",
      "Epoch 7/10\n",
      "224000/224000 [==============================] - 20s 91us/step - loss: 0.0467 - acc: 0.9826 - val_loss: 0.0389 - val_acc: 0.9861\n",
      "Epoch 8/10\n",
      "224000/224000 [==============================] - 20s 90us/step - loss: 0.0462 - acc: 0.9827 - val_loss: 0.0367 - val_acc: 0.9858\n",
      "Epoch 9/10\n",
      "224000/224000 [==============================] - 21s 92us/step - loss: 0.0455 - acc: 0.9833 - val_loss: 0.0374 - val_acc: 0.9861\n",
      "Epoch 10/10\n",
      "224000/224000 [==============================] - 20s 88us/step - loss: 0.0445 - acc: 0.9832 - val_loss: 0.0385 - val_acc: 0.9859\n",
      "80000/80000 [==============================] - 2s 23us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential  # for a sequential model \n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#import time\n",
    "\n",
    "dense_layer = 1\n",
    "layer_size = 128\n",
    "drop_layer = 0.3\n",
    "\n",
    "pred_cross = {}\n",
    "score = []\n",
    "#'fst-LEP-0.1-dr-128-l-1-de.model'\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for i in range(K):\n",
    "    \n",
    "    X_test = Xinterval[i]\n",
    "    X_train = coXinterval[i]\n",
    "    \n",
    "    \n",
    "    y_test = yinterval[i]\n",
    "    y_train = coyinterval[i]\n",
    "           \n",
    "    # Fit only to the training data\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    # Now apply the transformations to the data:\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "#    \n",
    "#    NAMEk = \"{}-fold-{}-dr-{}-l-{}-de-{}\".format(K,drop_layer, layer_size, dense_layer, int(time.time()))\n",
    "#    tensorboard = TensorBoard(log_dir = 'log/{}'.format(NAMEk))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer_size,input_shape = (int(14),)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(drop_layer))                                       # dropout 10% of the neurons\n",
    "    #           model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    #           model.add(Flatten())\n",
    "    for l in range(dense_layer):\n",
    "        model.add(Dense(layer_size))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(drop_layer))# dropout 10% of the neurons\n",
    "\n",
    "    model.add(Dense(4))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    #qual otimizador?\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "      optimizer='adam',\n",
    "      metrics=['accuracy'])\n",
    "\n",
    "    LEP_model = model.fit(X_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=10,\n",
    "              validation_split=0.3)#,\n",
    "#              callbacks=[tensorboard])\n",
    "\n",
    "    pred_cross[str(i)+'pred'] = model.predict(X_test)\n",
    "    score.append(model.evaluate(X_test,y_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc for K=5: 0.9855499999999999+-0.0005420447398508781\n"
     ]
    }
   ],
   "source": [
    "loss = [score[i][0] for i in range(K)]\n",
    "acc = [score[i][1] for i in range(K)]\n",
    "score\n",
    "print('acc for K={}: {}+-{}'.format(K,np.average(acc),np.std(acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.2485303e-06, 1.6784212e-04, 9.9975878e-01, 7.1142880e-05],\n",
       "       [1.9651507e-27, 6.2029181e-22, 1.8989266e-07, 9.9999976e-01],\n",
       "       [1.7280138e-08, 9.9866068e-01, 1.3392995e-03, 2.9823321e-11],\n",
       "       ...,\n",
       "       [5.7212600e-22, 8.6932970e-19, 5.2090604e-06, 9.9999475e-01],\n",
       "       [1.0197239e-10, 9.9990273e-01, 9.7308504e-05, 4.1542975e-14],\n",
       "       [9.9999917e-01, 1.4263951e-13, 8.2667162e-07, 1.2711623e-31]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(K):\n",
    "    pred_cross[i] = pd.DataFrame(pred_cross[str(i)+'pred'])\n",
    "\n",
    "pred_cross['2pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_prob=[]\n",
    "for i in range(K):\n",
    "    y_pred.append([np.argmax(pred_cross[str(i)+'pred'][j]) for j in range(len(y_test))]) #  10 x 40000 array\n",
    "    y_prob.append([np.max(pred_cross[str(i)+'pred'][j]) for j in range(len(y_test))])    # 10 x 40000  array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998092"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob[4][39999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_y_test = pd.DataFrame({'y_test':y_test})\n",
    "pd_y_prob = {}\n",
    "pd_y_pred = {}\n",
    "for i in range(K):\n",
    "    pd_y_prob['y_prob'+str(i)] = y_prob[i]\n",
    "    pd_y_pred['y_pred'+str(i)] = y_pred[i]\n",
    "    \n",
    "pd_y_prob = pd.DataFrame(pd_y_prob)\n",
    "pd_y_pred = pd.DataFrame(pd_y_pred)\n",
    "\n",
    "df_final = pd.concat([pd_y_test,pd_y_pred,pd_y_prob], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred0</th>\n",
       "      <th>y_pred1</th>\n",
       "      <th>y_pred2</th>\n",
       "      <th>y_pred3</th>\n",
       "      <th>y_pred4</th>\n",
       "      <th>y_prob0</th>\n",
       "      <th>y_prob1</th>\n",
       "      <th>y_prob2</th>\n",
       "      <th>y_prob3</th>\n",
       "      <th>y_prob4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999608</td>\n",
       "      <td>0.994854</td>\n",
       "      <td>0.999759</td>\n",
       "      <td>0.999843</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.806677</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998661</td>\n",
       "      <td>0.992724</td>\n",
       "      <td>0.999976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999910</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993960</td>\n",
       "      <td>0.999874</td>\n",
       "      <td>0.999501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.999294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_test  y_pred0  y_pred1  y_pred2  y_pred3  y_pred4   y_prob0   y_prob1  \\\n",
       "0       3        0        2        2        1        3  0.999608  0.994854   \n",
       "1       2        2        3        3        2        2  0.806677  0.999936   \n",
       "2       0        0        0        1        2        0  1.000000  1.000000   \n",
       "3       2        1        3        2        1        2  0.999910  1.000000   \n",
       "4       3        0        0        1        3        3  0.999999  0.999904   \n",
       "\n",
       "    y_prob2   y_prob3   y_prob4  \n",
       "0  0.999759  0.999843  1.000000  \n",
       "1  1.000000  0.999983  0.999139  \n",
       "2  0.998661  0.992724  0.999976  \n",
       "3  0.993960  0.999874  0.999501  \n",
       "4  0.999294  1.000000  1.000000  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the DATA :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving df_final\n",
    "\n",
    "#import pickle\n",
    "\n",
    "#pickle_out = open(\"5-fold-data-LEP.pickle\",\"wb\")\n",
    "#pickle.dump(df_final, pickle_out)\n",
    "#pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred0</th>\n",
       "      <th>y_pred1</th>\n",
       "      <th>y_pred2</th>\n",
       "      <th>y_pred3</th>\n",
       "      <th>y_pred4</th>\n",
       "      <th>y_prob0</th>\n",
       "      <th>y_prob1</th>\n",
       "      <th>y_prob2</th>\n",
       "      <th>y_prob3</th>\n",
       "      <th>y_prob4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999608</td>\n",
       "      <td>0.994854</td>\n",
       "      <td>0.999759</td>\n",
       "      <td>0.999843</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.806677</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998661</td>\n",
       "      <td>0.992724</td>\n",
       "      <td>0.999976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999910</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993960</td>\n",
       "      <td>0.999874</td>\n",
       "      <td>0.999501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.999294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999328</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.999627</td>\n",
       "      <td>0.628046</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.999887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.999674</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>0.999884</td>\n",
       "      <td>0.762106</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.999420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999072</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999856</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_test  y_pred0  y_pred1  y_pred2  y_pred3  y_pred4   y_prob0   y_prob1  \\\n",
       "0       3        0        2        2        1        3  0.999608  0.994854   \n",
       "1       2        2        3        3        2        2  0.806677  0.999936   \n",
       "2       0        0        0        1        2        0  1.000000  1.000000   \n",
       "3       2        1        3        2        1        2  0.999910  1.000000   \n",
       "4       3        0        0        1        3        3  0.999999  0.999904   \n",
       "5       1        0        0        2        0        1  0.999979  1.000000   \n",
       "6       2        1        1        2        0        2  0.999901  0.999627   \n",
       "7       1        2        3        0        3        1  0.999940  0.999674   \n",
       "8       2        1        2        3        2        2  0.999917  0.999884   \n",
       "9       0        0        0        2        3        0  0.999072  0.999982   \n",
       "\n",
       "    y_prob2   y_prob3   y_prob4  \n",
       "0  0.999759  0.999843  1.000000  \n",
       "1  1.000000  0.999983  0.999139  \n",
       "2  0.998661  0.992724  0.999976  \n",
       "3  0.993960  0.999874  0.999501  \n",
       "4  0.999294  1.000000  1.000000  \n",
       "5  0.999328  0.999999  0.999926  \n",
       "6  0.628046  0.999951  0.999887  \n",
       "7  0.999999  1.000000  0.999851  \n",
       "8  0.762106  0.999968  0.999420  \n",
       "9  0.999856  1.000000  1.000000  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "pickle_in = open(\"5-fold-data-LEP.pickle\",\"rb\")\n",
    "df_fin = pickle.load(pickle_in)\n",
    "df_fin.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd_y_test = pd.DataFrame( {'y_test':df_fin['y_test']})\n",
    "y_pred = [df_fin['y_pred'+str(i)] for i in range(K)]\n",
    "y_prob = [df_fin['y_prob'+str(i)] for i in range(K)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final00 = pd.concat([pd_y_test,pd.DataFrame({'y_pred':y_pred[0]}),pd.DataFrame({'y_prob':y_prob[0]})], axis=1)\n",
    "df_final11 = pd.concat([pd_y_test,pd.DataFrame({'y_pred':y_pred[1]}),pd.DataFrame({'y_prob':y_prob[1]})], axis=1)\n",
    "df_final22 = pd.concat([pd_y_test,pd.DataFrame({'y_pred':y_pred[2]}),pd.DataFrame({'y_prob':y_prob[2]})], axis=1)\n",
    "df_final33 = pd.concat([pd_y_test,pd.DataFrame({'y_pred':y_pred[3]}),pd.DataFrame({'y_prob':y_prob[3]})], axis=1)\n",
    "df_final44 = pd.concat([pd_y_test,pd.DataFrame({'y_pred':y_pred[4]}),pd.DataFrame({'y_prob':y_prob[4]})], axis=1)\n",
    "df_list =[df_final00,df_final11,df_final22,df_final33,df_final44] #40000 test events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_test  y_pred    y_prob\n",
       "0       3       3  1.000000\n",
       "1       2       2  0.999139\n",
       "2       0       0  0.999976\n",
       "3       2       2  0.999501\n",
       "4       3       3  1.000000"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list[4].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPR = []\n",
    "FPR = []\n",
    "\n",
    "TPR_final = []\n",
    "FPR_final = []\n",
    "for i in range(K): \n",
    "    df_list_0 = pd.DataFrame({})\n",
    "    df_list_1 = pd.DataFrame({})\n",
    "    df_list_2 = pd.DataFrame({})\n",
    "    df_list_3 = pd.DataFrame({})\n",
    "    \n",
    "#    df_list_0 = df_list[i][df_list[i]['y_test'] == 0]\n",
    "#    df_list_1 = df_list[i][df_list[i]['y_test'] == 1]\n",
    "#    df_list_2 = df_list[i][df_list[i]['y_test'] == 2]\n",
    "#    df_list_3 = df_list[i][df_list[i]['y_test'] == 3]\n",
    "    \n",
    "    shift = 500\n",
    "    sh = 0\n",
    "    threshold = [sh + (1-sh)*((i+1)/shift) for i in range(shift)]\n",
    "    count_0_ROC = []\n",
    "    count_1_ROC = []\n",
    "    count_2_ROC = []\n",
    "    count_3_ROC = []\n",
    "\n",
    "    countf_0_ROC = []\n",
    "    countf_1_ROC = []\n",
    "    countf_2_ROC = []\n",
    "    countf_3_ROC = []\n",
    "\n",
    "    for thr in threshold:\n",
    "        \n",
    "        #count the True positive of class-0,1, 2 and 3:\n",
    "        n0tp_ROC = df_list[i][(df_list[i]['y_test'] == 0) & (df_list[i].y_pred == 0) & (df_list[i].y_prob > thr)].count()        \n",
    "        n1tp_ROC = df_list[i][(df_list[i]['y_test'] == 1) & (df_list[i].y_pred == 1) & (df_list[i].y_prob > thr)].count()        \n",
    "        n2tp_ROC = df_list[i][(df_list[i]['y_test'] == 2) & (df_list[i].y_pred == 2) & (df_list[i].y_prob > thr)].count()\n",
    "        n3tp_ROC = df_list[i][(df_list[i]['y_test'] == 3) & (df_list[i].y_pred == 3) & (df_list[i].y_prob > thr)].count()\n",
    "\n",
    "        #count the False negative of class-0,1, 2 and 3:\n",
    "        n0fn_ROC = df_list[i][(df_list[i]['y_test'] == 0) & (df_list[i].y_pred == 0) & (df_list[i].y_prob < thr)].count()\n",
    "\n",
    "        n1fn_ROC = df_list[i][(df_list[i]['y_test'] == 1) & (df_list[i].y_pred == 1) & (df_list[i].y_prob < thr)].count() \n",
    "        \n",
    "        n2fn_ROC = df_list[i][(df_list[i]['y_test'] == 2) & (df_list[i].y_pred == 2) & (df_list[i].y_prob < thr)].count() \n",
    "        \n",
    "        n3fn_ROC = df_list[i][(df_list[i]['y_test'] == 3) & (df_list[i].y_pred == 3) & (df_list[i].y_prob < thr)].count()             \n",
    "        \n",
    "\n",
    "        # false positive of class-0,1, 2 and 3:\n",
    "        n0fp_ROC = df_list[i][(df_list[i]['y_test'] != 0) & (df_list[i].y_pred == 0) & (df_list[i].y_prob > thr)].count()\n",
    "        n1fp_ROC = df_list[i][(df_list[i]['y_test'] != 1) & (df_list[i].y_pred == 1) & (df_list[i].y_prob > thr)].count()  \n",
    "        n2fp_ROC = df_list[i][(df_list[i]['y_test'] != 2) & (df_list[i].y_pred == 2) & (df_list[i].y_prob > thr)].count()  \n",
    "        n3fp_ROC = df_list[i][(df_list[i]['y_test'] != 3) & (df_list[i].y_pred == 3) & (df_list[i].y_prob > thr)].count()  \n",
    "\n",
    "       # true negative of class-0,1, 2 and 3:\n",
    "        n0tn_ROC = df_list[i][(df_list[i]['y_test'] != 0) & (df_list[i].y_pred != 0) & (df_list[i].y_prob < thr)].count()\n",
    "        n1tn_ROC = df_list[i][(df_list[i]['y_test'] != 1) & (df_list[i].y_pred != 1) & (df_list[i].y_prob < thr)].count() \n",
    "        n2tn_ROC = df_list[i][(df_list[i]['y_test'] != 2) & (df_list[i].y_pred != 2) & (df_list[i].y_prob < thr)].count() \n",
    "        n3tn_ROC = df_list[i][(df_list[i]['y_test'] != 3) & (df_list[i].y_pred != 3) & (df_list[i].y_prob < thr)].count() \n",
    "\n",
    "\n",
    "    #    #creating a list with the results for TPR and FPR:\n",
    "        \n",
    "        count_0_ROC.append(n0tp_ROC[0]/(n0tp_ROC[0] + n0fn_ROC[0] ))   #TPR = TP/(TP  + FN)\n",
    "        count_1_ROC.append(n1tp_ROC[0]/(n1tp_ROC[0] + n1fn_ROC[0] )) \n",
    "        count_2_ROC.append(n2tp_ROC[0]/(n2tp_ROC[0] + n2fn_ROC[0] ))     \n",
    "        count_3_ROC.append(n3tp_ROC[0]/(n3tp_ROC[0] + n3fn_ROC[0] ))     \n",
    "\n",
    "        countf_0_ROC.append( n0fp_ROC[0]/(n0tn_ROC[0]+ n0fp_ROC[0] ))     #FPR = FP / (FP + TN)  \n",
    "        countf_1_ROC.append( n1fp_ROC[0]/(n1tn_ROC[0]+ n1fp_ROC[0] ))\n",
    "        countf_2_ROC.append( n2fp_ROC[0]/(n2tn_ROC[0] + n2fp_ROC[0] ))\n",
    "        countf_3_ROC.append(n3fp_ROC[0]/(n3tn_ROC[0]+ n3fp_ROC[0] ))\n",
    "\n",
    "    \n",
    "    \n",
    "        TPR =[count_0_ROC,count_1_ROC,count_2_ROC,count_3_ROC]\n",
    "        FPR = [countf_0_ROC,countf_1_ROC,countf_2_ROC,countf_3_ROC]\n",
    "        \n",
    "    TPR_final.append(TPR)\n",
    "    FPR_final.append(FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.average([TPR_final[i][3][19]for i in range(K)] )  # K x class x thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPR_ave = []\n",
    "FPR_ave = []\n",
    "for i in range(len(CATEGORIES)):\n",
    "    ccc=[]\n",
    "    ddd=[]\n",
    "    for j in range(shift):\n",
    "        ccc.append(np.average([TPR_final[k][i][j] for k in range(K)]))\n",
    "        ddd.append(np.average([FPR_final[k][i][j] for k in range(K)]))\n",
    "    TPR_ave.append(ccc)\n",
    "    FPR_ave.append(ddd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPR_std = []\n",
    "FPR_std = []\n",
    "for i in range(len(CATEGORIES)):\n",
    "    ccc=[]\n",
    "    ddd=[]\n",
    "    for j in range(shift):\n",
    "        ccc.append(np.std([TPR_final[k][i][j] for k in range(K)]))\n",
    "        ddd.append(np.std([FPR_final[k][i][j] for k in range(K)]))\n",
    "    TPR_std.append(ccc)\n",
    "    FPR_std.append(ddd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1f8daf0cc18>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY+TGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f8dae7fe10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_lin = np.linspace(0., 1, shift)\n",
    "number = len(CATEGORIES)\n",
    "cmap = plt.get_cmap('gnuplot')\n",
    "colors = [cmap(i) for i in np.linspace(0, 1, number)]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_lin, x_lin , '--',color = 'gray')\n",
    "for j , color in enumerate(colors, start=0):\n",
    "    plt.plot(FPR_ave[j],TPR_ave[j],color = color,label= CATEGORIES[j])#xerr=FPR_std[j],\n",
    "    plt.errorbar(FPR_ave[j],TPR_ave[j],yerr=TPR_std[j],color = color,alpha=0.4)\n",
    "    plt.legend(loc='lower right',fontsize=10)\n",
    "plt.xlabel('FPR%')\n",
    "plt.ylabel('TPR%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC parameter : Electron:0.7999474887646882+-5.187713678145928e-10\n",
      "AUC parameter : Muon:0.724573735598428+-3.602215918207911e-13\n",
      "AUC parameter : Tau:0.7012339942923979+-3.2358704156963667e-13\n",
      "AUC parameter : Quark:0.8192454954889842+-4.145071803506032e-10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pylab import *\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "def func(x, b ):\n",
    "\n",
    "    return(np.tanh(b*x))\n",
    "\n",
    "# data \n",
    "x_0 = np.array(FPR_ave[0])\n",
    "x_1 = np.array(FPR_ave[1])\n",
    "x_2 = np.array(FPR_ave[2])\n",
    "x_3 = np.array(FPR_ave[3])\n",
    "\n",
    "y_0 = np.array(TPR_ave[0])\n",
    "y_1 = np.array(TPR_ave[1])\n",
    "y_2 = np.array(TPR_ave[2])\n",
    "y_3 = np.array(TPR_ave[3])\n",
    "\n",
    "# curve fit [with only y-error]\n",
    "popt_0, pcov_0 = curve_fit(func, x_0, y_0) # ,sigma=1./(noise_0*noise_0)\n",
    "perr_0 = np.sqrt(np.diag(pcov_0))\n",
    "popt_1, pcov_1 = curve_fit(func, x_1, y_1) # ,sigma=1./(noise_1*noise_1)\n",
    "perr_1 = np.sqrt(np.diag(pcov_1))\n",
    "popt_2, pcov_2 = curve_fit(func, x_2, y_2) # ,sigma=1./(noise_2*noise_2)\n",
    "perr_2 = np.sqrt(np.diag(pcov_2))\n",
    "popt_3, pcov_3 = curve_fit(func, x_3, y_3) # ,sigma=1./(noise_2*noise_2)\n",
    "perr_3 = np.sqrt(np.diag(pcov_3))\n",
    "\n",
    "\n",
    "fit_0 = func(x_0, popt_0)\n",
    "fit_1 = func(x_1, popt_1)\n",
    "fit_2 = func(x_2, popt_2)\n",
    "fit_3 = func(x_3, popt_3)\n",
    "from scipy import integrate\n",
    "#f0=func(x,popt_0)\n",
    "AUC_0 = integrate.quad(func, 0, 1,args=popt_0)\n",
    "AUC_1 = integrate.quad(func, 0, 1,args=popt_1)\n",
    "AUC_2 = integrate.quad(func, 0, 1,args=popt_2)\n",
    "AUC_3 = integrate.quad(func, 0, 1,args=popt_3)\n",
    "print('AUC parameter :',str(CATEGORIES[0])+ ':'+ str(AUC_0[0]) + '+-' + str(AUC_0[1]) )\n",
    "print('AUC parameter :',str(CATEGORIES[1])+ ':' +str(AUC_1[0]) + '+-' + str(AUC_1[1]) )\n",
    "print('AUC parameter :',CATEGORIES[2]+ ':' + str(AUC_2[0]) + '+-' + str(AUC_2[1]) )\n",
    "print('AUC parameter :',CATEGORIES[3]+ ':' + str(AUC_3[0]) + '+-' + str(AUC_3[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
